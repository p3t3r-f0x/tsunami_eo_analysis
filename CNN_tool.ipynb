{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d56abe",
   "metadata": {},
   "source": [
    "# CNN Tool\n",
    "\n",
    "### 2643977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import rasterio\n",
    "from rasterio.plot import plotting_extent, show, show_hist, reshape_as_image\n",
    "from rasterio.mask import mask\n",
    "import os\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "from terrafm import terrafm_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011470fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_reflectance(band):\n",
    "    \"\"\"\n",
    "    Convert a band from digitized to reflectance. \n",
    "    Works for bands 1-7 only.\n",
    "    \"\"\"\n",
    "    mult_parameter = 2.75e-05\n",
    "    add_parameter = -0.2\n",
    "    return band * mult_parameter + add_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18190c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(folder_name : str, area_of_interest : geopandas.GeoDataFrame, bands = [1, 2, 3, 4]):\n",
    "\n",
    "    \"\"\" \n",
    "    Read in and preprocess raster data from a specified folder path.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing raster band files.\n",
    "    area_of_interest (geopandas.GeoDataFrame): GeoDataFrame defining the area to crop the raster data.\n",
    "    create_new (bool): Whether to create a new combined raster file. Defaults to True.\n",
    "    new_file_name (str): Name for the new combined raster file. Required if create_new is True.\n",
    "    bands (list): List of band numbers to process. Defaults to [1, 2, 3, 4].\n",
    "\n",
    "    Returns:\n",
    "    rasterio.DatasetReader: The combined raster data after preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_destination = \"data/combined_rasters\"\n",
    "    band_number_str = str(len(bands))\n",
    "    folder_path = os.path.join(\"data/\", folder_name)\n",
    "    new_file_name = f\"{folder_name}_{band_number_str}_bands_processed.tif\"\n",
    "    new_file_path = os.path.join(file_destination, new_file_name)\n",
    "    does_file_exist = os.path.exists(new_file_path)\n",
    "    \n",
    "    if not does_file_exist:\n",
    "\n",
    "        band_data_combined = []\n",
    "        for band in bands:\n",
    "            band_substring = f\"_B{band}\"\n",
    "            # find band file in folder\n",
    "            band_file = [f for f in os.listdir(folder_path) if band_substring in f][0]\n",
    "            band_path = os.path.join(folder_path, band_file)\n",
    "            # read in band file\n",
    "            with rasterio.open(band_path) as band_data:\n",
    "\n",
    "                area_of_interest = area_of_interest.to_crs(band_data.crs)\n",
    "                \n",
    "                cropped_band_data, transform = mask(band_data, area_of_interest.geometry, crop=True)\n",
    "                cropped_reflectance_band_data = convert_to_reflectance(cropped_band_data)\n",
    "                band_data_combined.append(cropped_reflectance_band_data)\n",
    "\n",
    "                meta = band_data.meta.copy()\n",
    "                meta.update(\n",
    "                    {                    \n",
    "                        \"transform\": transform,\n",
    "                        \"height\":cropped_reflectance_band_data.shape[1],\n",
    "                        \"width\":cropped_reflectance_band_data.shape[2],\n",
    "                        \"count\":len(bands),\n",
    "                        \"dtype\": cropped_reflectance_band_data.dtype\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            print(f\"Band {band} done\")\n",
    "\n",
    "        combined_bands_final = np.vstack(band_data_combined)\n",
    "\n",
    "        with rasterio.open(new_file_path, \"w\", **meta) as dest:\n",
    "            dest.write(combined_bands_final)\n",
    "\n",
    "        combined_bands_final = rasterio.open(new_file_path)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        combined_bands_final = rasterio.open(new_file_path)\n",
    "\n",
    "    return combined_bands_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46615d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion from 7 bands to 12 to be read into terrafm model\n",
    "\n",
    "def landsat5_to_terrafm_channels(x):\n",
    "    \"\"\"\n",
    "    x: (H, W, 7) Landsat 5 TM array (scaled)\n",
    "       Band order: [B1, B2, B3, B4, B5, B6(thermal), B7]\n",
    "\n",
    "    returns: (H, W, 12) TerraFM-compatible array\n",
    "    \"\"\"\n",
    "    H, W, _ = x.shape\n",
    "    out = np.zeros((H, W, 12), dtype=x.dtype)\n",
    "\n",
    "    # Sentinel-2-like mapping\n",
    "    out[..., 1]  = x[..., 0]  # Blue  (L5 B1)\n",
    "    out[..., 2]  = x[..., 1]  # Green (L5 B2)\n",
    "    out[..., 3]  = x[..., 2]  # Red   (L5 B3)\n",
    "    out[..., 7]  = x[..., 3]  # NIR   (L5 B4)\n",
    "    out[..., 10] = x[..., 4]  # SWIR1 (L5 B5)\n",
    "    out[..., 11] = x[..., 6]  # SWIR2 (L5 B7)\n",
    "    out[..., 8] = x[..., 3] \n",
    "\n",
    "    # All others remain zero:\n",
    "    # coastal, red-edge, water vapor\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dcb529",
   "metadata": {},
   "source": [
    "## ML Classification Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1fb37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_for_analysis = \"pre_tsunami\" # these names must match folder names (max 3)\n",
    "\n",
    "geojson_area_of_interest = geopandas.read_file(\"data/east_coast_map.geojson\") # set to path for geojson file for area of analysis focus \n",
    "\n",
    "bands_for_classification = [1, 2, 3, 4, 5, 6, 7]  # which bands to use for classification\n",
    "\n",
    "k_clusters = 6  # number of clusters for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946918a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pre-processed data\n",
    "\n",
    "raster = preprocess_data(folder_name = file_for_analysis, area_of_interest = geojson_area_of_interest, bands = bands_for_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping files to work with model\n",
    "\n",
    "x = np.moveaxis(raster.read(), 0, -1)\n",
    "print(x.shape)\n",
    "height = x.shape[0]\n",
    "width = x.shape[1]\n",
    "band_number = x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34eacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing data and reformatting\n",
    "\n",
    "x_data = x.reshape(-1, band_number)\n",
    "scaler = StandardScaler().fit(x_data)\n",
    "x_scaled = scaler.transform(x_data).astype(np.float32)\n",
    "\n",
    "x_scaled_img = x_scaled.reshape(height, width, band_number)\n",
    "x_scaled_img = landsat5_to_terrafm_channels(x_scaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to patches to align with terrafm model input\n",
    "\n",
    "PATCH = 224\n",
    "\n",
    "pad_h = (PATCH - height % PATCH) % PATCH\n",
    "pad_w = (PATCH - width % PATCH) % PATCH\n",
    "\n",
    "x_scaled_img_pad = np.pad(\n",
    "    x_scaled_img,\n",
    "    ((0, pad_h), (0, pad_w), (0, 0)),\n",
    "    mode=\"reflect\"\n",
    ")\n",
    "\n",
    "H2, W2, _ = x_scaled_img_pad.shape\n",
    "print(\"Padded shape:\", x_scaled_img_pad.shape)\n",
    "\n",
    "patches = []\n",
    "coords = []\n",
    "\n",
    "for y in range(0, H2, PATCH):\n",
    "    for x in range(0, W2, PATCH):\n",
    "        patch = x_scaled_img_pad[y:y+PATCH, x:x+PATCH, :]\n",
    "        patches.append(patch)\n",
    "        coords.append((y, x))\n",
    "\n",
    "patches = np.stack(patches)   # (N, 224, 224, B)\n",
    "print(\"Total patches:\", patches.shape[0])\n",
    "\n",
    "patches_torch = torch.tensor(\n",
    "    patches,\n",
    "    dtype=torch.float32\n",
    ").permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57433656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in terrafm model\n",
    "\n",
    "device = 'cpu'\n",
    "model = terrafm_base()\n",
    "state = torch.load(\"TerraFM-B.pth\", map_location=device)\n",
    "model.load_state_dict(state, strict=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded TerraFM on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating embeddings to split into batches\n",
    "\n",
    "embeddings = []\n",
    "batch_size = 8\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(patches_torch), batch_size):\n",
    "        batch = patches_torch[i:i+batch_size].to(device)\n",
    "        emb = model(batch)             \n",
    "        embeddings.append(emb.cpu().numpy())\n",
    "\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans clustering\n",
    "\n",
    "kmeans = KMeans(n_clusters=k_clusters, n_init=20, random_state=2)\n",
    "labels = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b18c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification map\n",
    "\n",
    "class_map = np.zeros((H2, W2), dtype=np.uint8)\n",
    "\n",
    "for (y, x), label in zip(coords, labels):\n",
    "    class_map[y:y+PATCH, x:x+PATCH] = label\n",
    "\n",
    "class_map = class_map[:height, :width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot map\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(class_map, cmap=\"tab20\")\n",
    "plt.title(f\"TerraFM Unsupervised Classification {file_for_analysis.replace('_', ' ').title()}\")\n",
    "plt.colorbar(label=\"Cluster ID\")\n",
    "plt.xlabel(\"X (patches)\")\n",
    "plt.ylabel(\"Y (patches)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
